# Regression {#regression}

#### In brief

> Regression is just a fancy term for drawing the 'best-fitting' line through a
> scatter-plot, and summarising how well the line describes the data.

> When doing regression in R, the relationship between an **_outcome_** and one
> or more **_predictors_** is described using a **_formula_**. When a model is
> '**_fitted_**' to a sample it becomes tool to make **_predictions_** for
> future samples. It also allows us to quantify our **_uncertainty_** about
> those predictions.

> **_Coefficients_** are numbers telling us how strong the relationshsips
> between predictors and outcomes are. But the meaning of coefficients depend on
> the study **_design_**, and the **_assumptions_** were are prepared to make.
> Causal diagrams can help us choose models and interpret our results.

> Multiple regression is a technique which can describe the relationship between
> **_one outcome_** and **_two or more predictors_**. We can also use multiple
> regression to describe cases where two variable **_interact_**. That is, when
> the effect of one predictor is increased or decreased by another. Multiple
> regression is important because it allows us to make more realistic models and
> better predictions.

> Like any sharp tool, regression should be used carefully. If our statistical
> model doesn't match the underlying network of causes and effects, or if we
> have used a biased sample, we can be misled.

## Session 1

We will revise core concepts for selecting and interpreting linear models. Some
of the material may have been covered in undergraduate courses, but we will
emphasise understanding and mastery of key ideas before we progress further.

## Session 2

We extend to examples requiring multiple regression, and interpretation of
interaction coefficients. We also cover prediction from models.

## Session 3

We cover statistical testing for individual coefficients and for interactions
using frequentist methods (regular _p_ values).

<!-- Bayes or Frequentist? -->
