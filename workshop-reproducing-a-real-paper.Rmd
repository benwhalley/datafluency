---
title: 'Reproducing a real paper'
author: 'Ben Whalley'
date: "September 2020"
bibliography: [references.bib]
biblio-style: apa6
link-citations: yes
output: 
  webex::html_clean:
    includes:
      after_body: footer.html
---



```{r, echo=F, include=F}
knitr::opts_chunk$set(echo = TRUE, collapse=TRUE, cache=TRUE, comment=">", message=FALSE)
library(tidyverse)
library(webex)
library(pander)
theme_set(theme_minimal())
```


> Reproducing a published analysis of data that authors have shared is an important 
> part of open science. Published reports are often quite sparse, and journals don't 
> provide enough space for exploratory analyses, alternative formulations models, or for sensitivity analyses.

> Replicating a published analysis is important in it's own right (because it gives us)
> more confidence in the results. But it can also be useful in developing new research
> or making new discoveries based on existing data. Researchers conducing systematic
> reviews may also want to replicate analyses to obtain additional information — e.g.
> data on effect sizes or variability — to use in meta analyses.

> Replicating published analyses can often be surprisingly tricky. Authors often don't provide full
> information about their data processing or model specification, so it can take some guesswork.
> It's also quite common to find errors in published analyses, which can be confusing.

> The final coursework assignment for this module is to try and replicate a published analyses. 
> Our intention is that this experience will give you a realistic experience of working with real data,
> and also an heightended awareness of the value of adopopting good practices for open and replicable science.




# Before you start


:::{.exercise}

1. Before you start make sure you are familiar with the material we have already covered on this module. In particular we will be using:

  - ggplot, including scatter plots and boxplots (see the [visualisation session](/datafluency/02-plotting.html))
  - `anovaBF` from the Bayes Factor package (see the [repeated measures session](/datafluency/workshop-repeated-measures.html))

1. Make a new R project for this activity (it will span multiple weeks). Give the project a descriptive name (e.g. `"psyc753-real-world-analysis"`)

1. Create a new .Rmd file inside the project. The first code chunk should load the tidyverse and BayesFactor packages.

:::








# Workshop tasks


Data for Schaefer 2018 are available from:
<https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0192758> (look in the supplementary information section).



:::{.exercise}

### New figures

In pairs:

- Using `ggplot`, make *two* different plots that best-illustrate the findings of the study.  One of the plots might be similar to a figure from the paper, as a starting point, but you should employ techniques
learnt in the course to increase the information density or provide some other enhancement.
  
Work together in a pair to make both plots.  When you have finished:

-  Compare and contrast the plots you have made. Think of at least 2 strengths of each, and 2 weaknesses, relative to the other. Discuss the design decisions you had to make: what features of the data were you trying to highlight, and how? Are there any features of both that you would like the change, or things you don't yet know how to do.

- Discuss your plots  with Paul or I. Please do highlight anything about your plots you would like to change but don't yet know how. If we are not immediately available feel free to move on to the next task before we get to you.

:::




:::{.exercise}

### Bayesian re-analysis

Find this section of the Schaeffer paper:

![](images/schaeffer-ftest.png)

Working pairs again,

- Agree, and write down a description, of the _type_ of analysis that is going on here. In particular it will help to think about the meaning of the *F* test highlighted in pink. Can you agree what this *F* test is telling us?

- Assuming we had variables in our model for `time`, the `placebo` group, and the `expectancy` group a partipant was in, write down a model formula that could be used to test an interaction in R. 
The [multiple regression](https://benwhalley.github.io/datafluency/05-multiple-regression-contin-by-categ.html) workshop first introduced the idea of interactions and we extended this in the session on [repeated measures or within subject Anova](https://benwhalley.github.io/datafluency/workshop-repeated-measures.html#interactions).

- If we want to run this model, what format would the data need to be in? Do the data shared by the authors match this? How can we process the data in the Excel file to match the format we need (try and do this now; feel free to check your results with Paul or I).

- Run a model which allows you to calculate the Bayesian equivalent of the F test highlighted in the paragraph above.


`r hide("Show me some hints about the data")`

- You need to make the data into long-form, with 2 rows per participant
- Your model will need to have 3 predictors, plus a variable which identifies the participant.

`r unhide()`




`r hide("Show me some hints about the model")`

- You will need to use the `anovaBF` function
- Remember to convert all categorical variables (including subject) to be a `factor`
- You need to set `whichRandom` to be the variable which identifies participants
- You will need to allow for interactions between all of the predictor variables (use the `*`)

`r unhide()`



`r hide("Finding the comparison we want")`

We previously [tested an interaction using `anovaBF`](/datafluency/workshop-repeated-measures.html). 

To do this we ran a model which included a `"*"` between each of our predictors. When we use a `"*"`, e.g. `outcome ~ var1 * var2` then R adds **three** terms to our model:

  - `var1`
  - `var2`
  - `var1:var2`
  
This last term is the **interaction**  between `var1` and `var2`. To test whether we have evidence for an interaction we can look at the Bayes Factor output. We need to find:

- A model which includes the interaction we are interested in (call this `full`)
- Another model which includes everything _except_ that interaction (call this `partial`)

To calculate the BF~10~ for the interaction itself we just divide the BF for the `full` model by the BF for the `partial` model.

In this simplified example we would find the BFs for the following models:

- `partial`:  `var1 + var2`
- `full`:  `var1 + var2 + var1:var2`

We'd then divide `full/partial` to get the BF for the interaction of `var1:var2`.

Check back to the within-subject Anova notes for a real example.

`r unhide()`




- Does your interpretation of the Bayesian analysis agree with the findings in the original paper?


```{r, include=F, eval=F}

library(readxl)
library(BayesFactor)

schaeffer <- read_xls('data/pone.0192758.s002.xls') 

schaeffer.long <- schaeffer %>% 
  rename(symptoms_pre = `pre symptoms (compositve score)`, symptoms_post=`post symptoms (compositve score)`) %>% 
  pivot_longer(cols = c(symptoms_pre, symptoms_post)) %>% 
  mutate(placebo=factor(`placebo (yes = 1)`), time=factor(name), expectancy=factor(`expectancy (yes = 1)`),
         subj = factor(patients))
  
schaeffer.bf <- anovaBF(value ~ time * placebo * expectancy + subj,
                        whichRandom = "subj", data=schaeffer.long)
schaeffer.bf 


# [8] placebo + time + expectancy 
# vs
# [9] placebo + time + placebo:time + expectancy
# this is the equivalent term to the F(1,42) = 5.42
schaeffer.bf[9]/schaeffer.bf[8]

# BF ~ 3.1, which means we have some evidence for the interaction — so the results agree.
```



:::









# Reference code and tips

Below are a collection of examples, based on things we have covered already, which may be useful as you complete the assessment.

These are _not_ a list of things you must work through. They are intended to be useful reminders of material we have covered already. In some places I extend what we have previously seen in ways that might be useful for the assessment task.

Use these snippets as a reference, if that's useful to you.  I will add to this page as questions arise in the course of the workshops.



## Downloading a file from the internet

Sometimes it is convenient to have a self-contained script which first downloads public data from the internet, and then uses this for an analysis; this saves the trouble of downloading the file to your computer, then uploading it to the RStudio server.

To do this use the `download.file` function:


```{r, cache=T}
download.file(url='https://github.com/benwhalley/datafluency/raw/master/data/pone.0192758.s002.xls', 
              destfile = 'pone.0192758.s002.xls')
```
**Explanation**:  `download.file`  does what it says on the tin. Pass the URL of the file to download, and the name you want to save it as in your folder on the RStudio server. If you run it it will save a copy of the remote file into your RStudio folder/project.

Watch out not to edit this saved file directly though. If you ran `download.file` a second time any changes made to `destfile` would be lost/overwritten. Use R to read in the file once and work with that imported data in an Rmd script. If you want to edit the file manually (e.g. in Excel) then make a copy of it first.



## Reading Excel files

The `readxl` library is useful for this:

```{r}
library(readxl)
read_xls('pone.0192758.s002.xls')
```

Some tips on file handling:

- Excel saves files with either either `.xls` (old style) or `.xlsx` (newer) file extensions. If you 
are uploading files to the RStudio server make sure you preserve these.

- If your Excel file has multiple 'sheets' then look at the help files for `read_xlx` and `read_xlsx`: They have options which let you specify which sheet you want, and whether to skip the first few rows or not (sometimes this can be useful)

- Save your own data in CSV format. It's easier and more reliable to work with.



:::{.exercise}

To practice, try loading in a datafile from a paper published with data on the Plos One journal.

Data files are normally saved in the 'supplementary materials' section.

Depending on your browser, you can often 'right click' on a link to get the URL (i.e. to get the URL of the data file to download).


:::



## Rounding numbers

For single numbers:

```{r}
round(3.141593, digits=2)
```

You can use `round` as part of mutate:

```{r}
mtcars %>% select(wt) %>% 
  mutate(wt_integer = round(wt, 0)) %>% 
  head()
```

And with this trick you can round multiple columns at once:

```{r}
mtcars %>% 
  select(drat, wt, qsec) %>% 
  mutate_if(is.numeric, round, digits=1)
```

**Explanation**: The `mutate_if` function is allowing us to selectively apply the `round` function to columns which hold numeric data. This is important because we can't round text data. The first part says `is.numeric`, which is used as the test to check which columns to mutate: if the column `is.numeric` then it will be mutated. The second part says `round`, which is the name of the function we want to apply to the columns. The final part says `digits=1`, which is an option that is passed to `round`. It means we will round each column to 1 decimal place. You can set digits to 2 or 3 for APA format tables.


How many digits to use? See http://my.ilstu.edu/~mshesso/apa_stats.htm


-----------------------------

One very small nitpick with rounding numbers is that `"3.10"` rounded to 1 decimal place would end up being displayed as `"3.1"`. That is, without a trailing zero.

Some people get annoyed by this because it sometimes makes tables look weird. If you want to output a fixed number of zeros you can use the `str_interp` function:

**Note this section is totally optional; you will not get marked down for using `round` as described above**.

```{r}
mtcars %>% 
  select(wt) %>% 
  rowwise() %>% 
  mutate(wt_fixed_width = str_interp("$[.2f]{wt}"))
```


**Explanation**: There are 3 important parts here. The `rowwise()` function is important, because it tells
R to format each row in turn, rather than attempting to format the whole column in one go. It's quite hard to explain in words, but to understand try running to code without and see what happens. The `str_interp` function is used to *interpolate* columns into a string (a column containing letters and numbers). The part which says `"$[.2f]{wt}"` can be broken into 3. The `$` says 'this is a variable', i.e. a column from the dataframe. The `"{wt}"` part tells R it is the `wt` column we want to use. The `"[.2f]"` tells R we want to use a fixed width (`f`) format, with 2 decimal places.

What's nice about `str_interp` is that it can also be used to make columns which contain a mix of numbers and text. 
Although this makes your data hard to process further, it can be useful for some table displays seen in journals.

```{r}
mtcars %>% 
  pivot_longer(everything(), names_to="Variable") %>% 
  group_by(Variable) %>% 
  summarise(Mean=mean(value), SD=sd(value)) %>% 
  rowwise() %>% 
  mutate(
    `Mean (SD)` =  str_interp("$[.2f]{Mean} ($[.2f]{SD})" )) %>% 
  pander()
```

**Explanation**: The only new part here is the format we used for `str_interp`: `"$[.2f]{Mean} ($[.2f]{SD})"`. This now has two `"$"` signs, and includes both the Mean and SD columns in a single column.

Don't do this if you expect to use your data for further analysis. It can be useful for making tables however.




## Pivoting


When you want to make a table that compares groups you can use a combination of:

- pivot_longer
- summarise
- pivot_wider

Sometimes you have to use multiple pivots to get the effect you want:

```{r}
diamonds %>% select(carat, depth, price, cut) %>% 
  pivot_longer(-cut) %>% 
  group_by(cut, name) %>% 
  summarise(mean = mean(value), sd = sd(value)) %>% 
  pivot_longer(mean:sd, names_to="variable") %>% 
  pivot_wider(names_from = cut)
```


:::{.exercise}

- Try running the code above step by step to check you understand what each part is doing
- Re-write the last line of code so that `carat`, `depth` and `price` appear in the column headings, as in the table below:


```{r, echo=F, message=F, warning=F}
diamonds %>% select(carat, depth, price, cut) %>% 
  pivot_longer(-cut) %>% 
  group_by(cut, name) %>% 
  summarise(mean = mean(value), sd = sd(value)) %>% 
  pivot_longer(mean:sd, names_to="variable") %>% 
  pivot_wider(names_from = cut)
```


:::





## Renaming columns

If you just want to rename columns:

```{r}
mtcars %>% 
  select(mpg, wt) %>% 
  rename(MPG = mpg, Weight=wt) %>% 
  head()
```


If you want to include spaces in your new column names, use backticks:

```{r}
mtcars %>% 
  select(mpg, wt) %>% 
  rename(`Miles per gallon` = mpg, `Weight in lbs`=wt) %>% 
  head()
```


But don't include spaces in column names if you plan on using the dataset for anything other than making a table.







## Working with text data


Sometimes you want to make things start with a capital letter, to make tables tidy:

```{r}
tibble(fruit = c("Apple", "orange", "banana")) %>% 
  mutate(fruit = tools::toTitleCase(fruit))
```



Another technique is to use `str_replace`. This function accepts a `string` (your variable containing letters and numbers) and a `pattern` and `replacement`. R searches through the string replacing all the text which matches the pattern with the replacement, as you can see below:

```{r}
tibble(times = c("time_1", "time_2", "time_3")) %>% 
  mutate(time_number = str_replace(string = times, pattern = "time_", replacement = ""))
```

There are some special characters you can use in the `pattern` variable to match more than one character at a time. This is a
pretty advanced technique, but can be very useful to know when working with text data. If you'd like to know more see [this](https://www.reddit.com/r/explainlikeimfive/comments/3yqvit/eli5_regex_regular_expressions/) for a very basic explanation, and [this](https://stackoverflow.com/questions/4736/learning-regular-expressions) for a bit more detail and pointers to other resources.






## Make tables with `pander`


So far we have used the Pander package to make tables in Rmarkdown:

```{r}
mtcars %>% 
  select(mpg, wt, cyl) %>% 
  head(3) %>% 
  pander()
```


You can add captions to tables like this:

```{r}
diamonds %>% 
  select(cut, clarity, carat) %>% 
  head(3) %>% 
  pander(caption="Some data about diamonds")
```


Sometimes you may fine that pander splits a table in two parts if it thinks the table will be too wide to display:


```{r}
mtcars %>% head(3) %>% pander()
```



To prevent this you can write:

```{r}
mtcars %>% head(3) %>% pander(split.tables=100)
```

The `split.tables=100` means, "only split the table if it's wider than 100 characters". You can set a larger number than 100 if you like, but that is pretty wide; if you make it much wider the results may not look that pretty.




## Rotate your axis labels


Sometimes axis labels don't fit neatly:

```{r}
europe <- gapminder::gapminder %>% 
  filter(continent=="Europe") %>% 
  ggplot(aes(country, gdpPercap)) + geom_boxplot() + xlab("") 

europe
```

There are two ways of fixing the plot. 

Sometimes `coord_flip` is helpful; it swaps the x and y axes so makes the labels easy to read:


```{r}
europe + coord_flip()
```

You can also just rotate the labels themselves:

```{r}
europe + theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1)) 
```




## Sorting the values on an axis

To continue the example above, sometimes we might want to see quickly which are the richest and poorest countries.

To do this you need to mutate the `country` variable using the `fct_recode` variable:

```{r}
gapminder::gapminder %>% 
  mutate(country = fct_reorder(country, gdpPercap)) %>% 
  filter(continent=="Europe") %>% 
  ggplot(aes(country, gdpPercap)) + geom_boxplot() + xlab("") + 
  coord_flip() 
```

Explanation: `fct_recode` takes the names of two columns: The factor you want to reorder, and the column containing the values the you want to reorder _by_ (here it's GDP).






