---
title: Data Visualisation
author: 'Ben Whalley'
# date: "September 2020"
# bibliography: [references.bib]
# biblio-style: apa6
link-citations: yes
output:
  webex::html_clean
---


```{r, include=F, echo=F, message=F}
source('_first_chunk.R')
```






![Nothing new under the sun: Mediaeval line plot, circa 1010. Image: [wikimedia](https://commons.wikimedia.org/wiki/File:Clm_14436_ecliptic_diagram.png)](images/Clm_14436_ecliptic_diagram.png)

----------------





```{r}

bmi %>% 
  filter(eq5d<1) %>% 
  ggplot(aes(bmi, eq5d)) + geom_smooth(method=lm) + 
  # geom_point(alpha=.05, position=position_jitter()) +
   facet_grid(~cut(age,8))

```




# Comparing categories

In the examples above we have been plotting continuous variables (and adding colours etc). We've
used density, scatter and smoothed line plots to do this.

Another common requirement is to use plots to compare summary statistics for different groups or
categories. For example, the classic plot in a psychology study looks like this:

```{r, echo=F, width=6, height=3}
set.seed(1234)
expdata <- expand.grid(Condition=LETTERS[1:3], stimuli=1:4, p=1:20) %>%
  mutate(RT = -200+rnorm(n(), 25 + 5*as.numeric(Condition=="A") + -4*as.numeric(stimuli==1), 6)^2, stimuli=factor(stimuli, labels=paste0("S", 1:4)))
write_csv(expdata, 'data/expdata.csv')
expdata <- read_csv('data/expdata.csv')
expdata %>%
  ggplot(aes(Condition, RT)) +
  stat_summary(geom='bar', fun.data=mean_se) +
  stat_summary(geom="errorbar", width=.2, fun.data=mean_se) + facet_wrap(~paste("Stimuli", stimuli))

```

However, there is evidence that readers often misinterpret bar plots. Specifically, the problem is
that we perceive values _within_ the bar area as more _likely_ than those just above, even though
this is not in fact the case.

A better choice is (almost always) to use a boxplot:

```{r}
expdata  %>%
  ggplot(aes(x=stimuli, y=RT)) + geom_boxplot()
```

**Explanation**: We used `Condition`, a category, as our x axis, and reaction times as the y axis.
We added `geom_boxplot` to show a boxplot.

:::{.tip}

If you're not familiar with boxplots, there are more details in the help files (type `?geom_boxplot`
into the console) or use the [wikipedia page here](https://en.wikipedia.org/wiki/Box_plot)

:::

:::{.exercise}

Load the (simulated) dataset called `expdata.csv`.

Either download the file and upload to your Rstudio project directory, or read it directly from this url: <https://gist.githubusercontent.com/benwhalley/f94baf447612e2434b181739dbba27df/raw/43df26022fff68f49918c795f27d7352dc0d3425/expdata.csv>

-   Recreate the boxplot above
-   Use a facet to recreate the plot you saw above, combining both `Condition` and `Stimuli`

:::


## Other data summary layers

If you _really_ need to plot the mean and standard error of different categories, ggplot has the
`stat_summary` command:

```{r}
expdata %>%
  ggplot(aes(Condition, RT)) + stat_summary()
```

**Explanation**: We used `Condition` and `RT` as our x and y axes, as before. This time we added
`stat_summary()` instead of `geom_boxplot()`. By default this plots the mean and standard error (a
measure of variability) in each group, using a **point-range plot**. This is better than a bar chart
because it avoids a known bias in how we read them. You can ignore the warning about
`No summary function supplied, defaulting to mean_se()` for now.

:::{.exercise}

As an extension exercise:

-   Adapt your facetted boxplot from above to show the mean and standard error instead
-   Can you combine both boxplot and summary in a single plot?

:::








# Real world plotting


```{r, include=F}
library(tidyverse)
library(webex)
knitr::opts_chunk$set(cache=T)
```

So far we have learned about `ggplot` and worked through lots of examples. You might have noticed
though: we focused mostly on the technique and didn't really think about what the data meant, or what the plots were trying to communicate.

In reality, given a dataset, you will need to work creatively to explore patterns and communicate results. Your decisions will be informed by:

-   Your research questions
-   Prior knowledge about the domain
-   Prior knowledge about the research design and the data collection process
-   What your learn about the data as you work (this is an interative process)

---

In these exercises we are going to work through a series of examples. Each time we will start with a
scenario which describes the domain and data collection, and some research questions we may have
had.

You should work in pairs (if possible) to:

-   Explore the dataset
-   Develop one or two plots which illustrate key features of the data

We will then join to form larger groups online to share findings, and justify decisions made.





::: {.exercise}

### Scenario 1: Secret agent

You are a MI6 agent, and have been sent a mystery dataset by one of your spies. She said it contains
highly important information which will be of great interest to your superiors. 

Use your ggplot wizardry to recover this classified information.

```{r, include=F}

dino <- read_tsv('data/DatasaurusDozen.tsv')

dino %>%
  rename(group=dataset) %>%
  mutate(group = as.numeric(factor(group))) %>%
  write_csv('data/mystery.csv')

df <- read_csv('data/mystery.csv')

df  %>%  ggplot(aes(x, y )) + geom_point() + facet_wrap(~group)

```

The data are available to download here: [data/mystery.csv](data/mystery.csv)


:::





::: {.exercise}

### Scenario 2: Admissions tutor

In the 1970s the University of California, Berkley, was concerned about the fairness of their
admissions procedures. They collected data from across the university for a number of years,
recording the:

-   Number of applicants
-   The department the student applied to
-   The students' gender
-   Number of students accepted
-   The percentage students of each gender who were accepted in each department

A summary of these data are available at this link: [data/berkley.csv](data/berkley.csv).

Your job is to:

-   Describe the pattern of applications
-   Decide if the university was fair in it's admissions procedures
-   Prepare a short presentation for the university governors which includes plots

Techniques/commands you might want to use:

-   `filter`
-   `group_by` and `summarise`
-   `stat_summary` to plot means and standard errors or deviations
-   `facet_wrap(~VARNAME)` to split a plot by a categorical variable



```{r, include=F, echo=F}
# don't re-run... probs added to this file by hand
# expand.grid(gender=c("Male", "Female"), department=LETTERS[1:6]) %>% mutate(p.admitted=NA, n.applicants=NA) %>% write_csv('data/berkley-setup.csv')

b <- read_csv("data/berkley-setup.csv")
set.seed(1234)
berkley <-  b %>% expand(year = 1976:1981, gender, department) %>%
  left_join(., b) %>%
  group_by(year) %>%
  mutate(
    n.applicants = n.applicants + rpois(n(), round(n.applicants*.3)),
    n.admitted = round(n.applicants * (p.admitted + runif(n(), -.1, .1))),
    percent.admitted = round(n.admitted / n.applicants * 100, 2)
  ) %>%
  select(-p.admitted)

berkley %>% write_csv('data/berkley.csv')
berkley <- read_csv('data/berkley.csv')
```

```{r, include=F, echo=F}
berkley %>%
  ggplot(aes(gender, n.admitted)) +
  stat_summary()
```

```{r, include=F, echo=F}
berkley  %>%
  ggplot(aes(gender, percent.admitted)) +
  stat_summary()
```

```{r, include=F, echo=F}
berkley %>%
  ggplot(aes(gender, n.applicants, group=department)) +
  stat_summary(fun.data=mean_se) +
  stat_summary(geom="line", fun.data=mean_se) +
  facet_grid(~department)
```

```{r, include=F, echo=F, fig.height=2}
berkley %>%
  ggplot(aes(gender, n.admitted, group=department)) +
  stat_summary(fun.data=mean_se) +
  stat_summary(geom="line", fun.data=mean_se) +
  facet_grid(~department)
```

```{r, include=F, echo=F}
berkley %>%
  ggplot(aes(gender, percent.admitted, group=department)) +
  stat_summary(fun.data=mean_se) +
  stat_summary(geom="line", fun.data=mean_se) +
  facet_grid(~department)
```


:::
